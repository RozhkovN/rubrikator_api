"""
FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∂–∞–ª–æ–±.

–ó–∞–ø—É—Å–∫:
    uvicorn api.main:app --reload --host 0.0.0.0 --port 8800
"""

import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Optional, List, Dict
import logging
import io

# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
import subprocess
import tempfile

# python-docx –¥–ª—è .docx
try:
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    logging.warning("python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ó–∞–≥—Ä—É–∑–∫–∞ .docx —Ñ–∞–π–ª–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")

# pypdf –¥–ª—è PDF
try:
    from pypdf import PdfReader
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    logging.warning("pypdf –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ó–∞–≥—Ä—É–∑–∫–∞ PDF —Ñ–∞–π–ª–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")

# olefile –¥–ª—è .doc
try:
    import olefile
    OLEFILE_AVAILABLE = True
except ImportError:
    OLEFILE_AVAILABLE = False
    logging.warning("olefile –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")

from src.model import ComplaintClassifier

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞–Ω–∏–µ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = FastAPI(
    title="–†—É–±—Ä–∏–∫–∞—Ç–æ—Ä –ñ–∞–ª–æ–± API",
    description="API –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∂–∞–ª–æ–± –ø–æ 20 —Ä—É–±—Ä–∏–∫–∞—Ç–æ—Ä–∞–º",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
classifier: Optional[ComplaintClassifier] = None


# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class ComplaintRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –∂–∞–ª–æ–±—ã"""
    text: str = Field(..., description="–¢–µ–∫—Å—Ç –∂–∞–ª–æ–±—ã", min_length=10)
    top_k: int = Field(1, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", ge=1, le=5)
    
    class Config:
        json_schema_extra = {
            "example": {
                "text": "–ë–∞–Ω–∫ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª –º–æ—é –∫–∞—Ä—Ç—É –±–µ–∑ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ 161-–§–ó",
                "top_k": 1
            }
        }


class PredictionItem(BaseModel):
    """–û–¥–∏–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    rubric_id: int
    rubric_name: str
    short_name: str
    response_template: str
    confidence: float


class ComplaintResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    text: str
    best_match: PredictionItem
    all_predictions: Optional[List[PredictionItem]] = None


class HealthResponse(BaseModel):
    """–û—Ç–≤–µ—Ç health check"""
    status: str
    model_loaded: bool


class TrainRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    model_name: str = Field(
        "paraphrase-multilingual-mpnet-base-v2",
        description="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Sentence Transformers"
    )
    use_keywords: bool = Field(True, description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
    keyword_weight: float = Field(0.3, description="–í–µ—Å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (0-1)", ge=0, le=1)
    
    class Config:
        json_schema_extra = {
            "example": {
                "model_name": "paraphrase-multilingual-mpnet-base-v2",
                "use_keywords": True,
                "keyword_weight": 0.3
            }
        }


class TrainResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å –æ–±—É—á–µ–Ω–∏—è"""
    status: str
    message: str
    model_path: str


# –°–æ–±—ã—Ç–∏—è –∂–∏–∑–Ω–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
@app.on_event("startup")
async def startup_event():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global classifier
    
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ API —Å–µ—Ä–≤–µ—Ä–∞...")
    
    try:
        model_path = root_dir / "models" / "classifier.pkl"
        
        if not model_path.exists():
            logger.warning(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
            logger.warning("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ POST /train –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
            classifier = None
        else:
            classifier = ComplaintClassifier()
            classifier.load(str(model_path))
            logger.info("‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        logger.warning("API –∑–∞–ø—É—â–µ–Ω –±–µ–∑ –º–æ–¥–µ–ª–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ POST /train –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        classifier = None


@app.on_event("shutdown")
async def shutdown_event():
    """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ"""
    logger.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ API —Å–µ—Ä–≤–µ—Ä–∞...")


# –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã
@app.get("/", tags=["General"])
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç"""
    return {
        "message": "–†—É–±—Ä–∏–∫–∞—Ç–æ—Ä –ñ–∞–ª–æ–± API",
        "version": "1.0.0",
        "docs": "/docs"
    }


@app.get("/health", response_model=HealthResponse, tags=["General"])
async def health():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è API"""
    return {
        "status": "ok",
        "model_loaded": classifier is not None
    }


@app.post("/classify", response_model=ComplaintResponse, tags=["Classification"])
async def classify_complaint(request: ComplaintRequest):
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∂–∞–ª–æ–±—ã.
    
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç –∂–∞–ª–æ–±—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ä—É–±—Ä–∏–∫–∞—Ç–æ—Ä.
    
    - **text**: –¢–µ–∫—Å—Ç –∂–∞–ª–æ–±—ã (–º–∏–Ω–∏–º—É–º 10 —Å–∏–º–≤–æ–ª–æ–≤)
    - **top_k**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1)
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - **best_match**: –õ—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —Ä—É–±—Ä–∏–∫–∞—Ç–æ—Ä–æ–º
    - **all_predictions**: –í—Å–µ —Ç–æ–ø-k —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–µ—Å–ª–∏ top_k > 1)
    """
    if classifier is None:
        raise HTTPException(
            status_code=503,
            detail="–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –°–µ—Ä–≤–µ—Ä –Ω–µ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ."
        )
    
    try:
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∂–∞–ª–æ–±—É
        result = classifier.predict(
            text=request.text,
            top_k=request.top_k,
            return_scores=False
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        predictions = []
        for pred in result['predictions']:
            predictions.append(PredictionItem(
                rubric_id=pred['rubric_id'],
                rubric_name=pred['rubric_name'],
                short_name=pred.get('short_name', ''),
                response_template=pred.get('response_template', ''),
                confidence=round(pred['confidence'], 4)
            ))
        
        response = ComplaintResponse(
            text=request.text,
            best_match=predictions[0],
            all_predictions=predictions if request.top_k > 1 else None
        )
        
        logger.info(f"‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {predictions[0].short_name} ({predictions[0].confidence:.2%})")
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}"
        )


@app.post("/classify/batch", tags=["Classification"])
async def classify_batch(complaints: List[str]):
    """
    –ü–∞–∫–µ—Ç–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∂–∞–ª–æ–±.
    
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –∂–∞–ª–æ–± –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π.
    """
    if classifier is None:
        raise HTTPException(
            status_code=503,
            detail="–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"
        )
    
    if len(complaints) > 100:
        raise HTTPException(
            status_code=400,
            detail="–ú–∞–∫—Å–∏–º—É–º 100 –∂–∞–ª–æ–± –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å"
        )
    
    try:
        results = classifier.predict_batch(complaints, top_k=1)
        
        responses = []
        for result in results:
            pred = result['best_match']
            responses.append({
                "text": result['text'],
                "rubric_id": pred['rubric_id'],
                "rubric_name": pred['rubric_name'],
                "short_name": pred.get('short_name', ''),
                "response_template": pred.get('response_template', ''),
                "confidence": round(pred['confidence'], 4)
            })
        
        return {"results": responses, "count": len(responses)}
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}"
        )


@app.post("/train", response_model=TrainResponse, tags=["Model Management"])
async def train_model(request: TrainRequest):
    """
    –û–±—É—á–µ–Ω–∏–µ (–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞) –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞.
    
    –°–æ–∑–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ä—É–±—Ä–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å.
    –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –≤ memory.
    
    - **model_name**: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Sentence Transformers
    - **use_keywords**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    - **keyword_weight**: –í–µ—Å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (0-1)
    
    –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ü—Ä–æ—Ü–µ—Å—Å –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
    (–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞).
    """
    global classifier
    
    try:
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        logger.info(f"   –ú–æ–¥–µ–ª—å: {request.model_name}")
        logger.info(f"   –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {request.use_keywords}")
        logger.info(f"   –í–µ—Å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {request.keyword_weight}")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        new_classifier = ComplaintClassifier(
            model_name=request.model_name,
            use_keywords=request.use_keywords,
            keyword_weight=request.keyword_weight
        )
        
        # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        model_path = root_dir / "models" / "classifier.pkl"
        
        # –û–±—É—á–∞–µ–º (—Å–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏)
        new_classifier.train(save_path=str(model_path))
        
        # –ó–∞–º–µ–Ω—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞ –Ω–æ–≤—ã–π
        classifier = new_classifier
        
        logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
        
        return TrainResponse(
            status="success",
            message="–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞",
            model_path=str(model_path)
        )
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}"
        )


@app.get("/model/info", tags=["Model Management"])
async def get_model_info():
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–∫—É—â–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏.
    """
    if classifier is None:
        return {
            "loaded": False,
            "message": "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
        }
    
    return {
        "loaded": True,
        "model_name": classifier.model_name,
        "use_keywords": classifier.use_keywords,
        "keyword_weight": classifier.keyword_weight,
        "semantic_weight": classifier.semantic_weight,
        "rubrics_count": len(classifier.rubrics)
    }


# ===================== –ó–ê–ì–†–£–ó–ö–ê –î–û–ö–£–ú–ï–ù–¢–û–í =====================

SUPPORTED_EXTENSIONS = ['.docx', '.doc', '.pdf']


def extract_text_from_docx(file_content: bytes) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ .docx —Ñ–∞–π–ª–∞.
    
    Args:
        file_content: –ë–∏–Ω–∞—Ä–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ .docx —Ñ–∞–π–ª–∞
    
    Returns:
        –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    if not DOCX_AVAILABLE:
        raise HTTPException(
            status_code=501,
            detail="python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-docx"
        )
    
    try:
        doc = Document(io.BytesIO(file_content))
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
        paragraphs = []
        for para in doc.paragraphs:
            text = para.text.strip()
            if text:
                paragraphs.append(text)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–∞–±–ª–∏—Ü
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    text = cell.text.strip()
                    if text:
                        paragraphs.append(text)
        
        full_text = "\n".join(paragraphs)
        return full_text
        
    except Exception as e:
        raise HTTPException(
            status_code=400,
            detail=f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è .docx —Ñ–∞–π–ª–∞: {str(e)}"
        )


def extract_text_from_pdf(file_content: bytes) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ PDF —Ñ–∞–π–ª–∞.
    
    Args:
        file_content: –ë–∏–Ω–∞—Ä–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ PDF —Ñ–∞–π–ª–∞
    
    Returns:
        –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    if not PDF_AVAILABLE:
        raise HTTPException(
            status_code=501,
            detail="pypdf –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pypdf"
        )
    
    try:
        reader = PdfReader(io.BytesIO(file_content))
        
        text_parts = []
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                text_parts.append(page_text.strip())
        
        full_text = "\n".join(text_parts)
        return full_text
        
    except Exception as e:
        raise HTTPException(
            status_code=400,
            detail=f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF —Ñ–∞–π–ª–∞: {str(e)}"
        )


def extract_text_from_doc(file_content: bytes) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ .doc —Ñ–∞–π–ª–∞ (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç Word).
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç antiword (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω) –∏–ª–∏ olefile –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è.
    
    Args:
        file_content: –ë–∏–Ω–∞—Ä–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ .doc —Ñ–∞–π–ª–∞
    
    Returns:
        –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º antiword (–ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
    try:
        with tempfile.NamedTemporaryFile(suffix='.doc', delete=False) as tmp_file:
            tmp_file.write(file_content)
            tmp_path = tmp_file.name
        
        try:
            result = subprocess.run(
                ['antiword', '-w', '0', tmp_path],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip()
        except (subprocess.SubprocessError, FileNotFoundError):
            pass  # antiword –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–±—É–µ–º olefile
        finally:
            import os
            os.unlink(tmp_path)
    except Exception:
        pass
    
    # –ü—Ä–æ–±—É–µ–º olefile –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
    if OLEFILE_AVAILABLE:
        try:
            ole = olefile.OleFileIO(io.BytesIO(file_content))
            
            # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ WordDocument stream
            if ole.exists('WordDocument'):
                # –ë–∞–∑–æ–≤–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–º)
                text_parts = []
                
                # –ò—â–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ—Ç–æ–∫–∏
                for stream in ole.listdir():
                    stream_name = '/'.join(stream)
                    if 'text' in stream_name.lower() or stream == ['WordDocument']:
                        try:
                            data = ole.openstream(stream).read()
                            # –ü—ã—Ç–∞–µ–º—Å—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç
                            try:
                                text = data.decode('utf-16-le', errors='ignore')
                                # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—á–∞—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
                                clean_text = ''.join(c for c in text if c.isprintable() or c in '\n\r\t ')
                                if len(clean_text) > 20:
                                    text_parts.append(clean_text)
                            except:
                                pass
                        except:
                            pass
                
                ole.close()
                
                if text_parts:
                    return "\n".join(text_parts)
            
            ole.close()
        except Exception as e:
            logger.warning(f"olefile –Ω–µ —Å–º–æ–≥ –ø—Ä–æ—á–∏—Ç–∞—Ç—å .doc: {e}")
    
    raise HTTPException(
        status_code=400,
        detail="–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ .doc —Ñ–∞–π–ª–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ .docx –∏–ª–∏ .pdf"
    )


def extract_text_from_file(filename: str, content: bytes) -> str:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞.
    
    Args:
        filename: –ò–º—è —Ñ–∞–π–ª–∞
        content: –ë–∏–Ω–∞—Ä–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
    
    Returns:
        –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    ext = filename.lower().rsplit('.', 1)[-1] if '.' in filename else ''
    
    if ext == 'docx':
        return extract_text_from_docx(content)
    elif ext == 'doc':
        return extract_text_from_doc(content)
    elif ext == 'pdf':
        return extract_text_from_pdf(content)
    else:
        raise HTTPException(
            status_code=400,
            detail=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: .{ext}. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: .docx, .doc, .pdf"
        )


@app.post("/classify/file", response_model=ComplaintResponse, tags=["Classification"])
async def classify_from_file(
    file: UploadFile = File(..., description="–î–æ–∫—É–º–µ–Ω—Ç —Å —Ç–µ–∫—Å—Ç–æ–º –∂–∞–ª–æ–±—ã (.docx, .doc, .pdf)"),
    top_k: int = 1
):
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∂–∞–ª–æ–±—ã –∏–∑ —Ñ–∞–π–ª–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª, –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∂–∞–ª–æ–±—É.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
    - **.docx** - Microsoft Word (—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
    - **.doc** - Microsoft Word (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
    - **.pdf** - PDF –¥–æ–∫—É–º–µ–Ω—Ç
    
    - **top_k**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1)
    """
    if classifier is None:
        raise HTTPException(
            status_code=503,
            detail="–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –°–µ—Ä–≤–µ—Ä –Ω–µ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ."
        )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    ext = file.filename.lower().rsplit('.', 1)[-1] if '.' in file.filename else ''
    if f'.{ext}' not in SUPPORTED_EXTENSIONS:
        raise HTTPException(
            status_code=400,
            detail=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: {', '.join(SUPPORTED_EXTENSIONS)}"
        )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–º–∞–∫—Å–∏–º—É–º 10 –ú–ë)
    content = await file.read()
    if len(content) > 10 * 1024 * 1024:
        raise HTTPException(
            status_code=400,
            detail="–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 10 –ú–ë"
        )
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
    text = extract_text_from_file(file.filename, content)
    
    if len(text.strip()) < 10:
        raise HTTPException(
            status_code=400,
            detail="–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (–º–µ–Ω–µ–µ 10 —Å–∏–º–≤–æ–ª–æ–≤)"
        )
    
    try:
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º
        result = classifier.predict(
            text=text,
            top_k=top_k,
            return_scores=False
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        predictions = []
        for pred in result['predictions']:
            predictions.append(PredictionItem(
                rubric_id=pred['rubric_id'],
                rubric_name=pred['rubric_name'],
                short_name=pred.get('short_name', ''),
                response_template=pred.get('response_template', ''),
                confidence=round(pred['confidence'], 4)
            ))
        
        response = ComplaintResponse(
            text=text,
            best_match=predictions[0],
            all_predictions=predictions if top_k > 1 else None
        )
        
        logger.info(f"‚úÖ –§–∞–π–ª {file.filename} –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω: {predictions[0].short_name}")
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}"
        )


class FileClassificationResult(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    filename: str
    text: str
    best_match: Optional[PredictionItem] = None
    all_predictions: Optional[List[PredictionItem]] = None
    error: Optional[str] = None


class FilesClassificationResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –ø–∞–∫–µ—Ç–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤"""
    results: List[FileClassificationResult]
    total: int
    success: int
    failed: int


@app.post("/classify/files", response_model=FilesClassificationResponse, tags=["Classification"])
async def classify_from_files(
    files: List[UploadFile] = File(..., description="–°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (.docx, .doc, .pdf)"),
    top_k: int = 1
):
    """
    –ü–∞–∫–µ—Ç–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∂–∞–ª–æ–± –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤.
    
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ 10 —Ñ–∞–π–ª–æ–≤, –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∫–∞–∂–¥—É—é –∂–∞–ª–æ–±—É.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
    - **.docx** - Microsoft Word (—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
    - **.doc** - Microsoft Word (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
    - **.pdf** - PDF –¥–æ–∫—É–º–µ–Ω—Ç
    
    - **files**: –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤, –º–∞–∫—Å–∏–º—É–º 10
    - **top_k**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ (1-5)
    """
    if classifier is None:
        raise HTTPException(
            status_code=503,
            detail="–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –°–µ—Ä–≤–µ—Ä –Ω–µ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ."
        )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º top_k
    if top_k < 1 or top_k > 5:
        raise HTTPException(
            status_code=400,
            detail="top_k –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1 –¥–æ 5"
        )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
    if len(files) > 10:
        raise HTTPException(
            status_code=400,
            detail="–ú–∞–∫—Å–∏–º—É–º 10 —Ñ–∞–π–ª–æ–≤ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å"
        )
    
    results = []
    success_count = 0
    failed_count = 0
    
    for file in files:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
            ext = file.filename.lower().rsplit('.', 1)[-1] if '.' in file.filename else ''
            if f'.{ext}' not in SUPPORTED_EXTENSIONS:
                results.append(FileClassificationResult(
                    filename=file.filename,
                    text="",
                    best_match=None,
                    all_predictions=None,
                    error=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: {', '.join(SUPPORTED_EXTENSIONS)}"
                ))
                failed_count += 1
                continue
            
            # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            content = await file.read()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
            if len(content) > 10 * 1024 * 1024:
                results.append(FileClassificationResult(
                    filename=file.filename,
                    text="",
                    best_match=None,
                    all_predictions=None,
                    error="–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 10 –ú–ë"
                ))
                failed_count += 1
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
            text = extract_text_from_file(file.filename, content)
            
            if len(text.strip()) < 10:
                results.append(FileClassificationResult(
                    filename=file.filename,
                    text=text,
                    best_match=None,
                    all_predictions=None,
                    error="–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π"
                ))
                failed_count += 1
                continue
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º
            result = classifier.predict(text=text, top_k=top_k, return_scores=False)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            predictions = []
            for pred in result['predictions']:
                predictions.append(PredictionItem(
                    rubric_id=pred['rubric_id'],
                    rubric_name=pred['rubric_name'],
                    short_name=pred.get('short_name', ''),
                    response_template=pred.get('response_template', ''),
                    confidence=round(pred['confidence'], 4)
                ))
            
            results.append(FileClassificationResult(
                filename=file.filename,
                text=text,
                best_match=predictions[0],
                all_predictions=predictions if top_k > 1 else None
            ))
            success_count += 1
            logger.info(f"‚úÖ –§–∞–π–ª {file.filename}: {predictions[0].short_name}")
            
        except Exception as e:
            results.append(FileClassificationResult(
                filename=file.filename,
                text="",
                best_match=None,
                all_predictions=None,
                error=str(e)
            ))
            failed_count += 1
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–∞–π–ª–∞ {file.filename}: {e}")
    
    return FilesClassificationResponse(
        results=results,
        total=len(files),
        success=success_count,
        failed=failed_count
    )


if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8800))
    uvicorn.run(app, host="0.0.0.0", port=port)
